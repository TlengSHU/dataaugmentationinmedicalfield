# Data Augmentation in Medical Field
Realization of some of my mentor's strategies on data augmentation in medical field
## Background
医疗领域使用深度学习的一个问题是数据量太少。图像数据的数据增强已有很实用的策略并被广泛使用，但是非图像数据的数据增强还没有。而我们现在有的数据比较特殊，它不是图像数据，但是数据之间仍存在位置上的关系。我们为这类数据设计了几种数据增强策略，并通过实验证明它们是否有效。
## The Data 
数据是人脑MRI扫描结果，一共有34个扫描的区域，被扫描后每个区域会给出一个数值，每个患者也就是一个记录给出TA四年的数据，也就是一共有34 * 4 个features，数据的label为一个分类结果，一共有五种，在这里就标为ABCDE。34个扫描区域还被分为6个lobes，每个lobes包括不同的区域。还有三个额外的feature包括患者性别，设备品牌等。
## Augmentation Strategic
### Combination
最初的策略，是将X个同类别的数据直接组合到一起来生成新的数据。该方法可以轻松生成大量数据，X的数量如果超过4，生成该策略所有可能数据就已经没有可能了。这个方法的问题，我认为是通过改变网络结构，我们能得到同样的效果。
### Kernel
#### Fixed Kernel
选择X * Y大小的kernel，将kernel中选定的区域替换成其他记录同样区域的数据。这种方法同样可以生成大量数据。我们原本数据为一维的长度为134的数据，在kernal替换策略中，我们需先将数据转换成4 * 34的二维数据。在这里我们在不同year之间的数据替换可能能保存疾病的一种变化趋势。
#### Fixed Kernels for Different Lobes
脑科学中将大脑一定区域归为一类，这每一类就称为一个lobe。因此为每一个lobe采用不同的kernel来生成数据显得非常合理，因为在同lobe的区域可能有更多的联系，替换生成的数据更接近该类别
#### Dynamic Kernels for Different Lobes
对应每一种类别的数据生成，采用不同的kernels。这样做的原因主要是为了解决数据的类别不均匀的问题，数据不均衡会导致训练出来的分类器是naive的--预测结果总是为比例最高的类别即可保证训练集的loss很低，同时如果采用是同样分布的测试集，该分类器的准确率Accuracy也会很高，但是一些类别的Precision和Recall会为0，这样的分类器显然不是我们想要的。其解决方式之一即使提供类别均衡的训练数据，而我们在数据增强的过程中正好可以做到这点。
#### Kernel not Replace but Add
将指定区域的数据加上其他记录同样区域的数据。这样做的理论基础我没有很理解，但是不妨碍我们多做几次尝试。
## Code
机器学习框架主要采用了Pytorch。目前的代码都为重构过的版本，虽然仍然存在很多软件开发中常见的问题，但比起之前已经好用很多了。
### Preprocess.py
对数据做最初的预处理，原始数据为.mat格式，读取后，经过一些操作返回.csv文件。
### Augmentation.py
实现了所有的数据增强策略，在前面说到的基础上，还实现了指定生成数量的实现版本，因为一些策略能产生的数据的量会超出我们的计算能力，因此生成一部分数据进行训练。
### Dataset.py
将生成的数据和测试数据组合好，得到一个可以被网络调用的DataLoader。
### Network.py
一个简单的多层全连接的神经网络的实现。我们可以调整各种超参数。
### Train.py
这是我们进行训练的主程序，我们可以在训练时调整各种参数和设置。
### RandomForest.py
使用随机森林对原始数据进行了训练，因为随机森林是一种十分适合数据量很少的情况下的机器学习算法。使用随机森林，我们能确保自己没有跑偏，得到连训练原始数据都不如的结果。
## Challenges and Solutions So Far
### Imbalanced Data
不平衡的数据集可能导致得到的分类器是Naive的，即预测结果始终为占比最多的类别，这确实是训练误差最小的分类器，同时如果测试集保持同样的分布，那么在该数据集上的准确率也会很高。但是对于不平衡的数据集，Accuracy准确率是一种非常片面的衡量标准，应该使用各个类别的Precision精准率和Recall召回率来衡量。
目前关于不平衡数据的解决方法有很多种观点，可以通过上采样，下采样或生成数据的方式来改变数据的分布，也可以对损失函数加权等等。改变数据分布的方式是有弊端的，丧失训练集中关于数据的分布的信息。
目前关于训练集不平衡的问题，我们目前采用的方式仍然是改变数据的分布，已我们的数据增强策略为主，上下采样为辅来得到平衡的数据集。对于测试集，我们特意选择了平衡的数据，为的是希望仅使用Accuracy准确率就能衡量分类器的优劣。
# To be continued



